{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reading journals from food critics\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will explore `how to use AI to analyze and classify journal entries from various food critics`. The objective is to determine whether the contents of these journal entries are related to food and restaurants. By leveraging a Language Learning Model (LLM), we can efficiently process unstructured text data and classify it based on its relevance to our topic of interest. This approach can be particularly useful for organizing and filtering large volumes of text data in various domains.\n",
    "\n",
    "\n",
    "### Unstructured data\n",
    "Text data like emails, journal entries, and social media posts often have no predefined structure. Additionally, each person writes in their own style: some use bullet points, while others prefer long paragraphs. For this reason, text data is known as **unstructured data**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>: What are the unstructured data?\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response Chatbot** : `Unstructured data` refers to information without a predefined model or structured framework, making it harder to process and store in traditional systems like relational databases. Characteristics include its lack of fixed schema, variety of formats (e.g., text, media, sensor data), large volumes, and the need for specialized tools like NLP or machine learning for analysis. Examples are emails, media files, web content, and customer feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing specific functions from the _helper_functions_ module:  \n",
    "  - The _print_llm_response_ function is likely used to print responses from a language learning model.  \n",
    "  - The _get_llm_response_ function is likely used to get responses from a language learning model.  \n",
    "\n",
    "- Importing specific functions from the _IPython.diplay_ module:  \n",
    "  -  _display_ is a function that allows you to display rich representations of Python objects directly in Jupyter Notebook cells, such as HTML, images, or Markdown text.  \n",
    "  -  _HTML_ is a class that wraps raw HTML code into a displayable object. It lets you render HTML content directly in a Jupyter Notebook cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing specific functions from the _helper_functions_ module\n",
    "from helper_functions import get_llm_response, print_llm_response\n",
    "\n",
    "\n",
    "# Importing specific functions from the _IPython.diplay_ module\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by examining journal entries stored as plain text files with a .txt extension. Let's open and read the `Cape Town journal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read Cape Town journal\n",
    "f = open(\"cape_town.txt\", \"r\")\n",
    "journal_cape_town = f.read()\n",
    "f.close()\n",
    "\n",
    "# Print the contents of the cape_town.txt file \n",
    "print(journal_cape_town)\n",
    "\n",
    "# Convert to HTML to get a better view of the contens of the selected file \n",
    "display(HTML(journal_cape_town))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As you can see, the file is about restaurants and food. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's open the `Tokyo journal` entry and read its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"tokyo.txt\", \"r\")\n",
    "journal_tokyo = f.read() \n",
    "f.close()\n",
    "\n",
    "# Print the contents of the tokyo.txt file \n",
    "print(journal_tokyo)\n",
    "\n",
    "# Convert to HTML to get a better view of the contens of the selected file \n",
    "display(HTML(journal_tokyo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output**: Also, this entry is about restaurants and food. However, notice how different the format of the journal is from the Cape Town example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining if text files are relevant using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you'll write a prompt that instructs an LLM to determine whether the content of a file is about food and restaurants or some other topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and include the Tokyo journal entry as the input data to check\n",
    "prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\": \n",
    "the journal describes restaurants and their specialties. \n",
    "\n",
    "Journal:\n",
    "{journal_tokyo}\"\"\"\n",
    "\n",
    "# Print the LLM response to see if the file is relevant for our purpose or not\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** To be drafted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and include the Cape Town journal entry as the input data to check\n",
    "prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\": \n",
    "the journal describes restaurants and their specialties. \n",
    "\n",
    "Journal:\n",
    "{journal_cape_town}\"\"\"\n",
    "\n",
    "\n",
    "# Print the LLM response to see if the file is relevant for our purpose or not\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** To be drafted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with multiple files texts, let's check them using a for loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking all files using a `for` loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python and an LLM together allows you to quickly iterate over multiple files and check the relevance of the content for your tasks. Start by creating a list of all the files you want to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the journal files\n",
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Relevant\n",
      "madrid.txt -> Not relevant\n",
      "rio_de_janeiro.txt -> Relevant\n",
      "sydney.txt -> Relevant\n",
      "tokyo.txt -> Relevant\n"
     ]
    }
   ],
   "source": [
    "# Use a for loop to open each file and have an LLM check if the content from that file is relevant to food and restaurants\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\": \n",
    "    the journal describes restaurants and their specialties. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : It seems that the Madrid journal entry is not relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print its contents to see why the LLM flagged it as \"not relevant\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madrid, as Spain's capital and largest city, is a key player in the nation's economy. Historically centered around its administrative functions, Madrid has evolved into a major financial hub, hosting the Madrid Stock Exchange and the headquarters of numerous national and international companies.\n",
      "\n",
      "The service sector, especially tourism, is vital to Madrid's economy. Millions of tourists visit annually, attracted by the city's cultural landmarks, museums, and vibrant nightlife. Additionally, trade fairs and conferences at venues like IFEMA (Feria de Madrid) bring significant business traffic.\n",
      "\n",
      "Innovation and technology are also growing sectors in Madrid. The city boasts a thriving startup ecosystem and hosts many tech companies, supported by a highly educated workforce from its universities and research institutions. This has spurred growth in IT, biotechnology, and renewable energy.\n",
      "\n",
      "Madrid's well-developed transportation network, including a comprehensive metro system, high-speed rail, and Adolfo SuÃƒÂ¡rez Madrid-Barajas Airport, enhances its role as a logistical and commercial hub. This connectivity supports trade and commerce, both within Spain and internationally, solidifying Madrid's status as a leading economic center in Europe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the content from any journal entry\n",
    "f = open(\"madrid.txt\", \"r\") \n",
    "print(f.read()) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Madrid journal entry doesn't contain information about restaurants to try. Instead, it is a description of the economy of the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "    <br><br>\n",
    "    I am using AI to determine whether different texts are \"relevant\" or \"not relevant\" using an LLM. Does this task have a specific name in AI?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response Chatbot** :  Yes, the task you are describing in AIâ€”using a language model to determine whether different texts are \"relevant\" or \"not relevant\"â€”is commonly known as `text classification` or `binary text classification` in machine learning.\n",
    "- Text Classification is  the task of assigning predefined categories or labels to a given text based on its content. In your case, the labels would be \"relevant\" and \"not relevant.\"\n",
    "- Binary Classification: Since you are only dealing with two possible outcomes (\"relevant\" or \"not relevant\"), this specific task is called binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "In this notebook, we demonstrated how to use an LLM to classify unstructured text data. By iterating over multiple journal entries, we could determine the relevance of the content to food and restaurants. This approach can be extended to various other classification tasks, making it a versatile tool for working with unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra practice\n",
    "\n",
    "Experiment with different prompts to check whether files are of interest to you or not. Try each exercise.\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Change the prompt to classify the text for different topics, for example `mentions a dessert` or `describes the restaurant design`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Yes\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> Yes\n",
      "tokyo.txt -> Yes\n"
     ]
    }
   ],
   "source": [
    "# Change the prompt to classify the text for different topics\n",
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes restaurants and food dishes. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt to verify whether it is mentioned at least a dessert\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a dessert. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As it can be seen from the prompt, only the text file \"rio_de_janeiro\" mentions `a dessert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Yes\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt to verify whether it is described the restaurant design\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes the restaurant design. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As it can be seen from the prompt, only the text file rio_de_janeiro does give some information about the design of the restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify this information, reviewing the text file rio_de_janeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"rio_de_janeiro.txt\", \"r\")\n",
    "journal_rio = f.read() \n",
    "f.close()\n",
    "\n",
    "# Convert to HTML to get a better view of the contens of the selected file \n",
    "display(HTML(journal_rio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt to verify whether it is described the restaurant design\n",
    "prompt = f\"\"\" Summarize the restaurant design from the following text \n",
    "in at most two sentences.\n",
    "\n",
    "Journal:\n",
    "{journal_rio}\"\"\"\n",
    "\n",
    "# Use LLM to determine if the journal entry is useful\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Using the same code below, change the prompt to classify into more than two categories.\n",
    "\n",
    "**Example:**\n",
    "- mentions a **vegetarian** dish\n",
    "- mentions a **vegan** dish\n",
    "- mentions both\n",
    "- mentions neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the prompt to classify the text for different topics\n",
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes restaurants and food dishes. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify into more than two categories and whether it is mentioned a **vegetarian** dish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a **vegetarian** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a vegetarian dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify into more than two categories and whether it is mentioned a **vegan** dish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a **vegan** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify whether it is mentioned both a **vegeterian** dish and **vegan** dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a **vegetarian** dish and a **vegan** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify whether it is not mentioned neither a **vegeterian** dish and **vegan** dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal not mentions a **vegetarian** dish and a **vegan** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** to be drafted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
