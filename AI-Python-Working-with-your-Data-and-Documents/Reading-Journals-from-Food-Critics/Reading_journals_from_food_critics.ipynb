{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reading journals from food critics ðŸ“–\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will explore `how to use AI to analyze and classify journal entries from various food critics`. The objective is to determine whether the contents of these journal entries are related to food and restaurants. By leveraging a Language Learning Model (LLM), we can efficiently process unstructured text data and classify it based on its relevance to our topic of interest. This approach can be particularly useful for organizing and filtering large volumes of text data in various domains.\n",
    "\n",
    "\n",
    "### Unstructured data\n",
    "Text data like emails, journal entries, and social media posts often have no predefined structure. Additionally, each person writes in their own style: some use bullet points, while others prefer long paragraphs. For this reason, text data is known as **unstructured data**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>: What are the unstructured data?\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response Chatbot** : `Unstructured data` refers to information without a predefined model or structured framework, making it harder to process and store in traditional systems like relational databases. Characteristics include its lack of fixed schema, variety of formats (e.g., text, media, sensor data), large volumes, and the need for specialized tools like NLP or machine learning for analysis. Examples are emails, media files, web content, and customer feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing specific functions from the _helper_functions_ module:  \n",
    "  - The _print_llm_response_ function is likely used to print responses from a language learning model.  \n",
    "  - The _get_llm_response_ function is likely used to get responses from a language learning model.  \n",
    "\n",
    "- Importing specific functions from the _IPython.diplay_ module:  \n",
    "  -  _display_ is a function that allows you to display rich representations of Python objects directly in Jupyter Notebook cells, such as HTML, images, or Markdown text.  \n",
    "  -  _HTML_ is a class that wraps raw HTML code into a displayable object. It lets you render HTML content directly in a Jupyter Notebook cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing specific functions from the _helper_functions_ module\n",
    "from helper_functions import get_llm_response, print_llm_response\n",
    "\n",
    "\n",
    "# Importing specific functions from the _IPython.diplay_ module\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by examining journal entries stored as plain text files with a .txt extension. Let's open and read the `Cape Town journal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "My first destination was The Test Kitchen, a restaurant that has earned its place among the world's best. Situated in the trendy Woodstock area, this dining spot is celebrated for its innovative dishes. I was particularly taken by their signature dish, the \"Pickled Fish Tacos.\" The tangy, flavorful fish wrapped in a soft taco, paired with a zesty salsa, was a delightful start to my culinary adventure. The industrial-chic ambiance added a modern edge to the dining experience.\n",
       "\n",
       "Next, I made my way to La Colombe, perched on the slopes of Constantia. Known for its refined and artistic approach to cuisine, La Colombe's \"Tuna La Colombe\" is a must-try. This dish features perfectly seared tuna, complemented by a delicate ponzu dressing and bursts of citrus. The presentation was as exquisite as the flavors, making it a memorable highlight of the day.\n",
       "\n",
       "At the bustling V&A Waterfront, I visited Harbour House for some of the freshest seafood in town. The \"Grilled Kingklip\" was a revelation. The succulent, flaky fish, grilled to perfection and served with a side of roasted vegetables, highlighted the ocean's bounty. The stunning views of the harbor added to the meal's appeal.\n",
       "\n",
       "Finally, my journey concluded at The Pot Luck Club, another gem in Woodstock. This trendy spot is known for its small plates, perfect for sharing. The standout dish was the \"Beef Tataki.\" Thinly sliced, seared beef with a tangy soy dressing and a hint of wasabi provided a burst of umami and heat. The eclectic, artistic vibe of the restaurant made for a fitting end to my culinary tour.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open and read Cape Town journal\n",
    "f = open(\"cape_town.txt\", \"r\")\n",
    "journal_cape_town = f.read()\n",
    "f.close()\n",
    "\n",
    "# Print the contents of the cape_town.txt file \n",
    "#print(journal_cape_town)\n",
    "\n",
    "# Convert to HTML to get a better view of the contens of the selected file \n",
    "display(HTML(journal_cape_town))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As you can see, the file is about restaurants and food. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's open the `Tokyo journal` entry and read its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tokyo's culinary landscape is nothing short of extraordinary. Each spot offers a unique taste of the city's diverse food culture. Here's a quick guide to some must-try places and dishes.\n",
       "\n",
       "    Sukiyabashi Jiro\n",
       "        Location: Ginza\n",
       "        Dish: Omakase sushi\n",
       "        Highlight: Impeccably crafted sushi made by the legendary Jiro Ono. Each piece is a masterclass in balance and flavor.\n",
       "\n",
       "    Ichiran Ramen\n",
       "        Location: Shibuya\n",
       "        Dish: Tonkotsu ramen\n",
       "        Highlight: A personal ramen booth for focused, uninterrupted enjoyment. Rich, creamy broth with perfectly cooked noodles.\n",
       "\n",
       "    Tsukiji Outer Market\n",
       "        Location: Tsukiji\n",
       "        Dish: Fresh sashimi and street food\n",
       "        Highlight: Vibrant market atmosphere. Indulge in ultra-fresh sashimi, grilled seafood, and other Japanese street food delights.\n",
       "\n",
       "    Narisawa\n",
       "        Location: Minato\n",
       "        Dish: Innovative tasting menu\n",
       "        Highlight: A fusion of French and Japanese techniques. Creative dishes with an emphasis on sustainability and local ingredients.\n",
       "\n",
       "    Ginza Kojyu\n",
       "        Location: Ginza\n",
       "        Dish: Kaiseki (traditional multi-course meal)\n",
       "        Highlight: Exquisite presentation and meticulous preparation. A journey through seasonal Japanese flavors.\n",
       "\n",
       "    Akasaka Kikunoi\n",
       "        Location: Akasaka\n",
       "        Dish: Kaiseki\n",
       "        Highlight: Elegant and serene setting. Seasonal ingredients transformed into artful, delicious courses.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(\"tokyo.txt\", \"r\")\n",
    "journal_tokyo = f.read() \n",
    "f.close()\n",
    "\n",
    "# Print the contents of the tokyo.txt file \n",
    "# print(journal_tokyo)\n",
    "\n",
    "# Convert to HTML to get a better view of the contens of the selected file \n",
    "display(HTML(journal_tokyo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output**: Also, this entry is about restaurants and food. However, notice how different the format of the journal is from the Cape Town example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining if text files are relevant using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you'll write a prompt that instructs an LLM to determine whether the content of a file is about food and restaurants or some other topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt and include the Tokyo journal entry as the input data to check\n",
    "prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\": \n",
    "the journal describes restaurants and their specialties. \n",
    "\n",
    "Journal:\n",
    "{journal_tokyo}\"\"\"\n",
    "\n",
    "# Print the LLM response to see if the file is relevant for our purpose or not\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output**  As it can ben seen from the output, in the above example, the content of a selected file has been classified relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt and include the Cape Town journal entry as the input data to check\n",
    "prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\": \n",
    "the journal describes restaurants and their specialties. \n",
    "\n",
    "Journal:\n",
    "{journal_cape_town}\"\"\"\n",
    "\n",
    "\n",
    "# Print the LLM response to see if the file is relevant for our purpose or not\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** As it can ben seen from the output, in the above example, the content of a selected file has been classified relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with multiple files texts, let's check them using a for loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking all files using a `for` loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python and an LLM together allows you to quickly iterate over multiple files and check the relevance of the content for your tasks. Start by creating a list of all the files you want to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the journal files\n",
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Relevant\n",
      "madrid.txt -> Not relevant\n",
      "rio_de_janeiro.txt -> Relevant\n",
      "sydney.txt -> Relevant\n",
      "tokyo.txt -> Relevant\n"
     ]
    }
   ],
   "source": [
    "# Use a for loop to open each file and have an LLM check if the content from that file is relevant to food and restaurants\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Relevant\" or \"Not relevant\": \n",
    "    the journal describes restaurants and their specialties. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As it can been seen from the output,  that the Madrid journal entry i has been classified not relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print its contents to see why the LLM flagged it as \"not relevant\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madrid, as Spain's capital and largest city, is a key player in the nation's economy. Historically centered around its administrative functions, Madrid has evolved into a major financial hub, hosting the Madrid Stock Exchange and the headquarters of numerous national and international companies.\n",
      "\n",
      "The service sector, especially tourism, is vital to Madrid's economy. Millions of tourists visit annually, attracted by the city's cultural landmarks, museums, and vibrant nightlife. Additionally, trade fairs and conferences at venues like IFEMA (Feria de Madrid) bring significant business traffic.\n",
      "\n",
      "Innovation and technology are also growing sectors in Madrid. The city boasts a thriving startup ecosystem and hosts many tech companies, supported by a highly educated workforce from its universities and research institutions. This has spurred growth in IT, biotechnology, and renewable energy.\n",
      "\n",
      "Madrid's well-developed transportation network, including a comprehensive metro system, high-speed rail, and Adolfo SuÃƒÂ¡rez Madrid-Barajas Airport, enhances its role as a logistical and commercial hub. This connectivity supports trade and commerce, both within Spain and internationally, solidifying Madrid's status as a leading economic center in Europe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the content from any journal entry\n",
    "f = open(\"madrid.txt\", \"r\") \n",
    "print(f.read()) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Madrid journal entry doesn't contain information about restaurants to try. Instead, it is a description of the economy of the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "    <br><br>\n",
    "    I am using AI to determine whether different texts are \"relevant\" or \"not relevant\" using an LLM. Does this task have a specific name in AI?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response Chatbot** :  Yes, the task you are describing in AIâ€”using a language model to determine whether different texts are \"relevant\" or \"not relevant\"â€”is commonly known as `text classification` or `binary text classification` in machine learning.\n",
    "- Text Classification is  the task of assigning predefined categories or labels to a given text based on its content. In your case, the labels would be \"relevant\" and \"not relevant.\"\n",
    "- Binary Classification: Since you are only dealing with two possible outcomes (\"relevant\" or \"not relevant\"), this specific task is called binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "In this notebook, we demonstrated how to use an LLM to classify unstructured text data. By iterating over multiple journal entries, we could determine the relevance of the content to food and restaurants. This approach can be extended to various other classification tasks, making it a versatile tool for working with unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra practice\n",
    "\n",
    "Experiment with different prompts to check whether files are of interest to you or not. Try each exercise.\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Change the prompt to classify the text for different topics, for example `mentions a dessert` or `describes the restaurant design`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Yes\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> Yes\n",
      "tokyo.txt -> Yes\n"
     ]
    }
   ],
   "source": [
    "# Change the prompt to classify the text for different topics\n",
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes restaurants and food dishes. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt to verify whether it is mentioned at least a dessert\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a dessert. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As it can be seen from the prompt, only the text file \"rio_de_janeiro\" mentions `a dessert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Yes\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt to verify whether it is described the restaurant design\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes the restaurant design. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** : As it can be seen from the prompt, only the text file rio_de_janeiro does give some information about the design of the restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify this information, reviewing the text file rio_de_janeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "First up was Confeitaria Colombo, a legendary and picturesque cafÃƒÂ© in central Rio. Known for its pastel de nata (custard tart), Colombo serves a delightful treat that is hard to beat. The crispy, flaky pastry filled with creamy, sweet custard was an excellent start to the day. The cafÃƒÂ©'s historic Belle Ãƒâ€°poque ambiance added an extra layer of charm.\n",
       "\n",
       "Next, I visited Fogo de ChÃƒÂ£o, a quintessential Brazilian steakhouse in Botafogo. Famous for its picanha (top sirloin), this churrascaria impressed with its perfectly grilled meat. The picanha was juicy, tender, and bursting with flavor, showcasing the high quality of Brazilian beef. The endless array of grilled meats served tableside made for a hearty and satisfying meal.\n",
       "\n",
       "For a more modern dining experience, I headed to Olympe in Lagoa. This Michelin-starred restaurant specializes in contemporary Brazilian cuisine. The highlight was their moqueca de caju (cashew nut stew). This rich and creamy stew, made from cashew nuts and complemented by fresh seafood and vegetables, was an exquisite dish in an elegant and refined setting.\n",
       "\n",
       "Finally, I concluded my culinary tour at AprazÃƒÂ­vel, renowned for its breathtaking views and farm-to-table approach. Their signature dish, galinhada (Brazilian chicken and rice), was outstanding. The tender and flavorful chicken, cooked with a mix of rice, vegetables, and spices, and served with farofa (toasted cassava flour), perfectly highlighted the fresh, locally sourced ingredients. The lush, garden-like setting of the restaurant provided a serene end to the culinary adventure.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open(\"rio_de_janeiro.txt\", \"r\")\n",
    "journal_rio = f.read() \n",
    "f.close()\n",
    "\n",
    "# Convert to HTML to get a better view of the contens of the selected file \n",
    "display(HTML(journal_rio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confeitaria Colombo features a historic Belle Ã‰poque ambiance, enhancing its charm as a cafÃ© known for its custard tarts. In contrast, Olympe offers a modern, elegant setting for contemporary Brazilian cuisine, while AprazÃ­vel boasts breathtaking views and a farm-to-table approach in a lush garden-like environment.\n"
     ]
    }
   ],
   "source": [
    "# Create prompt to verify whether it is described the restaurant design\n",
    "prompt = f\"\"\" Summarize the restaurant design from the following text \n",
    "in at most two sentences.\n",
    "\n",
    "Journal:\n",
    "{journal_rio}\"\"\"\n",
    "\n",
    "# Use LLM to determine if the journal entry is useful\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Using the same code below, change the prompt to classify into more than two categories.\n",
    "\n",
    "**Example:**\n",
    "- mentions a **vegetarian** dish\n",
    "- mentions a **vegan** dish\n",
    "- mentions both\n",
    "- mentions neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> Yes\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> Yes\n",
      "sydney.txt -> Yes\n",
      "tokyo.txt -> Yes\n"
     ]
    }
   ],
   "source": [
    "# Change the prompt to classify the text for different topics\n",
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes restaurants and food dishes. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify into more than two categories and whether it is mentioned a **vegetarian** dish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a **vegetarian** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a vegetarian dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify into more than two categories and whether it is mentioned a **vegan** dish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a **vegan** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify whether it is mentioned both a **vegeterian** dish and **vegan** dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal mentions a **vegetarian** dish and a **vegan** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the prompt to classify whether it is not mentioned neither a **vegeterian** dish and **vegan** dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cape_town.txt -> No\n",
      "madrid.txt -> No\n",
      "rio_de_janeiro.txt -> No\n",
      "sydney.txt -> No\n",
      "tokyo.txt -> No\n"
     ]
    }
   ],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal not mentions a **vegetarian** dish and a **vegan** dish. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation output** As it can been shown in the output, a list of each journal is given with the related classification whether it is vegeterian or not (yes, no, respectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
