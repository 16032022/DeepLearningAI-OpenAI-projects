{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lesson, you will learn how to install `third-party packages` using a command called `pip`. Once you have installed a package, you can use functions from the package by importing them using the `import` command. This notebook will guide you through the process of installing and using the `bs4` library (Beautiful Soup) for web scraping, as well as other useful packages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing packages using `pip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  ask chatbot why it's called bs4\n",
    "<p style=\"background-color:#F5C780; padding:15px\"> ü§ñ <b>Use the Chatbot</b>: Give a short description of bs4\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response Chatbot**: The `bs4 library`, also known as BeautifulSoup, is a Python package used for parsing HTML and XML documents. It is widely used for web scraping and helps in navigating, searching, and modifying the parse tree. Run the cell below to install the `bs4` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\michela\\l4c4\\.venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\michela\\l4c4\\.venv\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\michela\\l4c4\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Packages\n",
    "Now that you have installed the bs4 package, you can use it in your programs. First, you need to import the `BeautifulSoup` function from the bs4 package, as well as some other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\michela\\l9r\\.venv\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\michela\\l9r\\.venv\\lib\\site-packages (from beautifulsoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "#%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the BeautifulSoup class from the bs4 library, used for parsing and scraping HTML and XML content.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import the requests library, which allows sending HTTP requests to fetch content from the web.\n",
    "import requests \n",
    "\n",
    "# Import all functions and variables from a custom module named `helper_functions`. \n",
    "from helper_functions import * \n",
    "\n",
    "# Import `HTML` and `display` from IPython's `display` module to render HTML content and display it within a Jupyter Notebook.\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from the web\n",
    "\n",
    "In this section, you'll \"scrape\", or download HTML data from a website, in this case from a [Batch newsletter](https://www.deeplearning.ai/the-batch/) published by DeepLearning.AI. You'll use the `requests` Python package to download the data from the webpage and make it available in your program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# The URL from one of the Batch's newsletters\n",
    "url = 'https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/'\n",
    "\n",
    "# Getting the content from the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the response from the requests\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `<Response [200]>` you see is an indication from the requests library that your HTTP request was successful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have downloaded the content from the website, you can display it in the notebook using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michela\\L4c4\\.venv\\Lib\\site-packages\\IPython\\core\\display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/ width=\"60%\" height=\"400\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(f'<iframe src={url} width=\"60%\" height=\"400\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Text with Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll use `Beautiful Soup` to extract all the text paragraphs from the HTML structure that you retrieved, and save it as a single string. Here is the code to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® New course! Enroll in Building Towards Computer Use with Anthropic\n",
      "Dear friends,\n",
      "Last year, a number of large businesses and individuals went to the media and governments and pushed the message that AI is scary, impossible to control, and might even lead to human extinction. Unfortunately they succeeded: Now many people think AI is scary. But when I speak with regulators, media, and private citizens, I like to bring the issue of whether AI is beneficial or harmful back to a very basic question: Are we better off with more, or less, intelligence in the world?¬†\n",
      "Intelligence is the ability to apply skills and knowledge to make good decisions. Yes, intelligence can be used for nefarious purposes. But over many centuries, a major driver of civilization's progress has been people getting smarter and more educated. Until now, human intelligence has been the primary form of intelligence available. But with artificial intelligence, we have the opportunity to bring much more intelligence into the world. I discussed this opportunity in a recent¬†interview¬†(paywalled) with¬†Financial Times¬†reporter Ryan McMorrow.\n",
      "Historically, intelligence has been very expensive to acquire. It costs a lot to feed, raise, and train a broadly knowledgeable and experienced human being! That's why it‚Äôs so expensive to hire intelligence, such as a highly skilled doctor to examine and advise you on a medical condition, or a patient tutor who can understand your child and gently coach them where they need help. But with artificial intelligence, we have the potential to make intelligence cheap for everyone, so you no longer have to worry about a huge bill for seeing a doctor or educating your child.¬†\n",
      "For society's biggest problems, such as climate change, intelligence ‚Äî including artificial intelligence ‚Äî also has a significant role to play. While having more intelligence in the world isn't the only thing (there are also nuances such as how to share the wealth it creates, how it will affect jobs, and how to keep it from being used for evil purposes), I believe we are much better off as a society with more intelligence, be it human or artificial intelligence.¬†\n",
      "In my recent talk at TED AI (you can watch the 12-minute presentation¬†here), I touched on why I'm excited about AI and why I think many of the anxieties about it are misplaced. If you speak with someone who‚Äôs worried about AI, please forward the talk to them to see if it helps to reassure them. Or ask if they fundamentally believe we want more intelligence in the world. I find that answering this question can be a useful North Star for how we approach AI.\n",
      "Keep learning!\n",
      "Andrew\n",
      "P.S. Check out our new short course on ‚ÄúBuilding Applications with Vector Databases,‚Äù taught by Pinecone‚Äôs Tim Tully! Vector databases (DBs) are commonly associated with retrieval augmented generation (RAG) but actually have many uses in AI applications. In this course, you‚Äôll learn about (i) a basic semantic search app that uses a vector DB to find similar documents, (ii) a RAG application querying datasets it was not trained on, (iii) recommender systems that combine semantic search and RAG, (iv) hybrid search, which lets you work with dense and sparse vectors simultaneously, (v) anomaly detection applied to network logs, and (vi) an image-similarity application with a fun example that determines which parent a child resembles more. Come learn how you can use vector DBs to build many different types of applications!¬†Enroll here\n",
      "Stay updated with weekly AI News and Insights delivered to your inbox\n"
     ]
    }
   ],
   "source": [
    "# Using beautifulsoup to extract the text\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all the text in paragraph elements on the webpage\n",
    "all_text = soup.find_all('p')\n",
    "\n",
    "# Create an empty string to store the extracted text\n",
    "combined_text = \"\"\n",
    "\n",
    "# Iterate over 'all_text' and add to the combined_text string\n",
    "for text in all_text:\n",
    "    combined_text = combined_text + \"\\n\" + text.get_text()\n",
    "\n",
    "# Print the final combined text\n",
    "print(combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details about how this code works, you can ask the chatbot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ü§ñ <b>Use the Chatbot</b>:\n",
    "<br><br>\n",
    "What is the following code doing?\n",
    "<br><br>\n",
    "soup = BeautifulSoup(response.text, 'html.parser')<br>\n",
    "all_text = soup.find_all('p')\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Response Chatbot** : The code you provided is using BeautifulSoup to parse HTML content and extract all the <p> (paragraph) elements from a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting information from scraped website data using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass the text you just extracted from the Batch newsletter website to an LLM and ask it to extract the most relevant information for you. Start by writing the prompt and passing in the text you extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Extract the key bullet points from the following text.\n",
    "\n",
    "Text:\n",
    "{combined_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pass the prompt to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- New course: \"Building Towards Computer Use with Anthropic\"\n",
      "- AI perceived as scary due to media influence; focus on whether more intelligence is beneficial.\n",
      "- Intelligence defined as the ability to make good decisions; historically expensive to acquire.\n",
      "- AI has potential to make intelligence affordable and accessible.\n",
      "- AI can address major societal issues like climate change.\n",
      "- Emphasis on the importance of increasing intelligence in society.\n",
      "- Recent TED AI talk discusses excitement about AI and addresses common anxieties.\n",
      "- New short course on \"Building Applications with Vector Databases\" offered by Pinecone‚Äôs Tim Tully.\n",
      "- Course topics include semantic search, RAG applications, recommender systems, hybrid search, anomaly detection, and image similarity.\n",
      "- Encouragement to enroll and stay updated with AI news.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One more example of installing packages\n",
    "\n",
    "Throughout the courses so far, you've imported helper functions from a file called `helper_functions.py` using commands like `from helper_functions import get_llm_response`.\n",
    "\n",
    "The DeepLearning.AI team has created a third-party package called `aisetup` that you can use to access the helper functions from the course in your own code outside of this learning platform.\n",
    "\n",
    "To install it, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install aisetup \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the package is installed, you can import helper functions from it using the `import` command. For example, if you want to import `get_llm_response`, you now run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisetup import get_llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using the get_llm_response function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is named after the British comedy television show \"Monty Python's Flying Circus,\" which its creator, Guido van Rossum, enjoyed. The name reflects the language's emphasis on fun and readability.\n"
     ]
    }
   ],
   "source": [
    "response = get_llm_response(\"Why is the programming language called Python?\")\n",
    "\n",
    "# Print LLM's response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra practice\n",
    "\n",
    "Try the following exercises to test what you have learned. \n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Modify the following code to answer the following question:\n",
    "- Who built the new short course mentioned in the letter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new short course was built by Pinecone‚Äôs Tim Tully.\n"
     ]
    }
   ],
   "source": [
    "# Modify the prompt\n",
    "prompt = f\"\"\"Extract who built the new short course from the following text\n",
    "\n",
    "Text:\n",
    "{combined_text}\n",
    "\"\"\"\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the `celsius_to_fahrenheit` function in the `aisetup` package to calculate the Fahrenheit equivalent of 0 degrees Celsius. You'll need to complete the import statement and the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0¬∞C is equivalent to 32.00¬∞F\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Complete the import statement\n",
    "from aisetup import celsius_to_fahrenheit\n",
    "\n",
    "# Complete the calculation\n",
    "celsius_value = 0\n",
    "zero_celsius_in_fahrenheit = celsius_to_fahrenheit(celsius_value)\n",
    "print (zero_celsius_in_fahrenheit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge exercise!\n",
    "\n",
    "Write code that uses the `bs4` package to create a string that contains the **title element from the Batch newsletter**. This is the text that starts \"The World Needs More Intelligence\".\n",
    "\n",
    "**Hint 1:** Titles on webpages are often header elements, with tags like `<h1>` or `<h2>`.\n",
    "**Hint 2:** Ask the chatbot for help, using the code you have already written as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The World Needs More Intelligence Human intelligence is expensive, artificial intelligence is cheap. To solve big problems like climate change, it makes sense to double down on AI.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title = soup.find('h1').get_text()\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we explored how to install and use `third-party Python packages` like bs4 (Beautiful Soup) and aisetup. We learned how to scrape data from a webpage, extract relevant information, and use helper functions from a custom package. These skills are essential for web scraping and data analysis tasks, allowing you to efficiently gather and process data from various sources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
